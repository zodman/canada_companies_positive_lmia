init:
    wget "https://open.canada.ca/data/api/action/package_show?id=90fed587-1364-4f33-a9ee-208181dc0b97" --no-hsts -c -O out.json

start:
    rm -f  *.csv
    declare -a FILES=`cat out.json  | jq -r ".result.resources[].url" | grep -v "/Positive_Employers_EN.csv" | grep EN` 
    for f in ${FILES}; do
        red " "
        red  " Download $f"
        wget -c --no-hsts -q --show-progress $f
    done
    xlsx2csv TFWP_2020Q2_Positive_EN.xlsx > TFWP_2020Q2_Positive_EN.csv
    red " "
    red "Remove shit"
    sed -i 1d *.csv
    sed -i 1d 2015_Positive_Employers_EN.csv

fillempty:
    red "Fill empty columns"
    for f in *EN.csv; do
        red "Proccessing $f"
        python3 fillempty.py $f
    done

concat:
    declare -a FILES=`find . -iname '*.processed.csv' | xargs`
    red "merging files"
    rows csv-merge ${FILES} all.csv
    red "obtain schema"
    rows schema all.csv

convert:
    rm *.db
    rows csv-to-sqlite all.csv all.db 
    sqlite-utils enable-fts --fts4 all.db all employer occupations address  phase  province_territory  stream
    rows csv-to-sqlite global_stream.csv global_stream.db
    rows csv-to-sqlite reduced_global_stream.csv reduced_global_stream.db
#    rows csv-to-sqlite reduced_global_stream.csv.loc.csv reduced_global_stream.csv.loc.db
#   rows csv-to-sqlite reduced_global_stream.csv.joburl.csv reduced_global_stream.csv.joburl.db

replacestr:
    red "Replace heads"
    sed -i s/occupations_under_noc_2011/occupations/g *.processed.csv
    sed -i s/approved_positions/positions_approved/g *.processed.csv
    sed -i s/employer_name/employer/g *.processed.csv
    red "Replace head ocupations"
    sed -i s/occupaitons_under_noc_2012/occupations/g *.processed.csv
    sed -i s/occupaitons_under_noc_2011/occupations/g *.processed.csv
    sed -i s/,occupation,/,occupations,/g *.processed.csv
    red "Replace head stream"
    sed -i s/program_stream/stream/g *.processed.csv

globalstream:
    SQL="select * from table1 where stream like '%Global%'"
    rows query "${SQL}" all.csv --output global_stream.csv --samples 0

reduce:
    SQL=" select * from table1 where"
    SQL+=" ( lower(address) not like '%toronto%' and "
    SQL+=" lower(address) not like '%qu%bec%' and "
    SQL+=" lower(address) not like '%montr%al%' and "
    SQL+=" lower(address) not like '%vancouver%' ) and "
    SQL+=" ( lower(occupations) like '%comp%' or"
    SQL+=" lower(occupations) like '%soft%' )"
	echo ${SQL}
    rows query "${SQL}" global_stream.csv --output reduced_global_stream.csv
    rows query "select address,occupations from table1" reduced_global_stream.csv
fil:
    rows query "select distinct(employer) as e from table1 order by e desc " reduced_global_stream.csv  --output filtered.csv
    sed -i s/Inc.//g filtered.csv
    sed -i s/inc.//g filtered.csv
    sed -i s/\\.//g filtered.csv
    sed -i s/Ltd//g filtered.csv
    sed -i s/\\\"//g filtered.csv
    sed -i s/Technology//g filtered.csv
    sed -i s/Technologie//g filtered.csv

all: fillempty replacestr concat globalstream  reduce fil convert
complete: init start all

upload:
    rsync --progress -v *.db *.yml python3.ninja:apps/canada/
deploy: upload
    ssh zodman@python3.ninja sudo supervisorctl restart canada
