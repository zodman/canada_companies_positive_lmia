init:
    # step 1
    wget "https://open.canada.ca/data/api/action/package_show?id=90fed587-1364-4f33-a9ee-208181dc0b97" --no-hsts -c -O out.json
    rows convert "https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada/express-entry/eligibility/find-national-occupation-code.html" noc.csv

start:
    # step 2
    set -e
    declare -a FILES=`cat out.json  | jq -r ".result.resources[].url" | grep -ve "FR\|fr"` 
    for f in ${FILES}; do
        red " "
        red  " Download $f"
        wget -nc --no-hsts --quiet $f
    done
    for f  in *.xlsx; do
        xlsx2csv $f > "${f%.xlsx}.csv"
    done
    red " "
    red "Remove shit"
    sed -i.orig.orig 1d *.csv
    # sed -i.orig.orig 1d 2015_Positive_Employers_EN.csv
    rm 2015_positive_employers_en.csv*

fillempty:
    set -xe
    red "Fill empty columns"

    for f in *[^processed].csv; do
        red "Proccessing $f"
        python fillempty.py $f
    done

concat:
    set -xe
    rm -rf all.processed.csv
    declare -a FILES=`find . -iname '*.processed.csv' | xargs`
    red "merging files"
    rows csv-merge ${FILES} all.processed.csv
    red "obtain schema"
    rows schema all.processed.csv


convert:
    rm -rf *.db
    red "Finish step, generating db files"
    rows csv-to-sqlite all.processed.csv all.db 
    sqlite-utils enable-fts --fts4 all.db all employer occupations address  phase  province_territory  stream
    #rows csv-to-sqlite global_stream,sk.csv global_stream.db
    #rows csv-to-sqlite reduced_global_stream.csv reduced_global_stream.db
#    rows csv-to-sqlite reduced_global_stream.csv.loc.csv reduced_global_stream.csv.loc.db
#   rows csv-to-sqlite reduced_global_stream.csv.joburl.csv reduced_global_stream.csv.joburl.db

replacestr:
    red "Replace heads"
    sed -i.orig s/occupations_under_noc_2011/occupations/g *.processed.csv
    sed -i.orig s/approved_positions/positions_approved/g *.processed.csv
    sed -i.orig s/employer_name/employer/g *.processed.csv
    sed -i.origin s/newfoundland_and_labrador/employer/g *.processed.csv
    sed -i.origin s/approved_lmias/positions_approved/g *.processed.csv

    red "Replace head ocupations"
    sed -i.orig s/occupaitons_under_noc_2012/occupations/g *.processed.csv
    sed -i.orig s/occupaitons_under_noc_2011/occupations/g *.processed.csv
    sed -i.orig s/,occupation,/,occupations,/g *.processed.csv
    red "Replace head stream"
    sed -i.orig s/program_stream/stream/g *.processed.csv

globalstream:
    SQL="select * from table1 where stream like '%Global%'"
    rows query "${SQL}" all.processed.csv --output global_stream.processed.csv --samples 0

reduce:
    SQL=" select * from table1 where"
    SQL+=" ( lower(address) not like '%toronto%' and "
    SQL+=" lower(address) not like '%qu%bec%' and "
    SQL+=" lower(address) not like '%montr%al%' and "
    SQL+=" lower(address) not like '%vancouver%' ) and "
    SQL+=" ( lower(occupations) like '%comp%' or"
    SQL+=" lower(occupations) like '%soft%' )"
	echo ${SQL}
    rows query "${SQL}" global_stream.processed.csv --output reduced_global_stream.processed.csv
    rows query "select address,occupations from table1" reduced_global_stream.processed.csv

fil:
    rows query "select distinct(employer) as e from table1 order by e desc " reduced_global_stream.processed.csv  --output filtered.processed.csv
    sed -i.orig s/Inc.//g filtered.csv
    sed -i.orig s/inc.//g filtered.csv
    sed -i.orig s/\\.//g filtered.csv
    sed -i.orig s/Ltd//g filtered.csv
    sed -i.orig s/\\\"//g filtered.csv
    sed -i.orig s/Technology//g filtered.csv
    sed -i.orig s/Technologie//g filtered.csv

all: fillempty replacestr concat convert 

gts: all globalstream  reduce fil
complete: clean init start all

clean:
    set -xe
    rm -rf *.csv
    rm -rf *.json
    rm -rf *.orig
    rm -rf *.xlsx


upload: @interactive
    rsync --progress -v *.db *.yml python3.ninja:apps/canada/
deploy: upload @interactive
    ssh zodman@python3.ninja sudo supervisorctl restart canada

ee:
    rows convert https://www.canada.ca/en/immigration-refugees-citizenship/corporate/mandate/policies-operational-instructions-agreements/ministerial-instructions/express-entry-rounds.html  express_entry_draws.db
    rows schema express_entry_draws.db

